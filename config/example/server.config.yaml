# Shepherd 单机模式配置
# 此配置文件用于单机模式（standalone mode）

server:
    web_port: 9190
    anthropic_port: 9170
    ollama_port: 11434
    lmstudio_port: 1234
    host: 0.0.0.0
    read_timeout: 60
    write_timeout: 60

model:
    paths:
        - ./models
        - ~/.cache/huggingface/hub
    path_configs: []
    auto_scan: true
    scan_interval: 0

llamacpp:
    paths:
        - path: ./llama.cpp
          name: Default
          description: ""

download:
    directory: ./downloads
    max_concurrent: 4
    chunk_size: 1048576
    retry_count: 3
    timeout: 300

model_repo:
    endpoint: huggingface.co
    token: ""
    timeout: 30

security:
    api_key_enabled: false
    api_key: ""
    cors_enabled: true
    allowed_origins:
        - '*'

compatibility:
    ollama:
        enabled: true
        port: 11434
    lmstudio:
        enabled: false
        port: 1234

log:
    level: info
    format: json
    output: both
    directory: ./logs
    max_size: 100
    max_backups: 3
    max_age: 7
    compress: true

storage:
    type: sqlite
    sqlite:
        path: ./data/shepherd.db
        pragmas:
            cache_size: "-64000"
            synchronous: NORMAL
        enable_wal: true
    postgresql: null

# 运行模式
mode: standalone

# 节点配置（推荐使用）
node:
    id: auto
    name: ""
    role: standalone
    tags: []              # 节点标签，例如: ["gpu", "high-memory"]
    metadata:             # 节点元数据
        os: linux
        arch: amd64

    # Master 角色配置
    master_role:
        enabled: false  # 单机模式禁用 Master 角色
        port: 9190
        api_key: ""
        ssl:
            enabled: false
            cert_path: ""
            key_path: ""

    # Client 角色配置
    client_role:
        enabled: false  # 单机模式禁用 Client 角色
        master_address: ""
        register_retry: 3
        heartbeat_interval: 5
        heartbeat_timeout: 15

    # 资源监控配置
    resources:
        monitor_interval: 5
        report_gpu: true
        report_temperature: true
        gpu_backend: auto

    # 命令执行器配置
    executor:
        max_concurrent: 4
        task_timeout: 3600
        allow_remote_stop: true
        allowed_commands:
            - load_model
            - unload_model
            - run_llamacpp
            - stop_process
            - scan_models
            - collect_logs

    # 能力配置（Python 支持）
    capabilities:
        python_enabled: false
        conda_path: ""       # 例如: /home/user/miniconda3/bin/conda
        conda_environments:  # Conda 环境列表
            shepherd: ""

# 以下配置已废弃，仅为向后兼容保留
# 新配置请使用上面的 node 块
master:
    enabled: false
    client_config_dir: /home/user/workspace/Shepherd/config/clients
    network_scan:
        enabled: false
        subnets:
            - 192.168.1.0/24
            - 10.0.0.0/8
        port_range: 9191-9200
        timeout: 5
        auto_discover: false
        interval: 0
    scheduler:
        strategy: round_robin
        max_queue_size: 100
        task_timeout: 300
        retry_on_failure: true
        max_retries: 3
    log_aggregation:
        enabled: true
        max_buffer_size: 1048576
        flush_interval: 10

client:
    enabled: false
    master_address: ""
    client_info:
        id: ""
        name: ""
        tags: []
        metadata:
            arch: amd64
            os: linux
    heartbeat:
        interval: 30
        timeout: 90
    conda_env:
        enabled: false
        conda_path: ""
        environments:
            shepherd: ""
    register_retry: 3
    heartbeat_interval: 5
    heartbeat_timeout: 15
