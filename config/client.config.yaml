# Shepherd Client 配置文件
# Client 模式：作为工作节点连接到 Master

# Client 基本配置
client:
  # Client 名称
  name: client-1
  # Client 标签（用于任务分配）
  tags:
    - gpu
    - rocm
  # 描述
  description: "AMD GPU Worker"

# Master 连接配置
master:
  # Master 服务器地址
  address: http://192.168.1.100:9190
  # 注册 Token（如果 Master 启用了认证）
  token: ""
  # 心跳间隔（秒）
  heartbeat_interval: 30
  # 重连延迟（秒）
  reconnect_delay: 5
  # 最大重连次数（-1 表示无限）
  max_reconnect_attempts: -1

# 日志配置
log:
  level: info
  format: json
  output: both
  directory: ./logs
  max_size: 100
  max_backups: 3
  max_age: 7
  compress: true

# 模型配置
model:
  paths:
    - /home/user/workspace/Shepherd/models
    - /home/user/.cache/huggingface/hub
  auto_scan: true
  scan_interval: 0

# llama.cpp 配置
llamacpp:
  paths:
    - path: /home/user/workspace/Shepherd/llama.cpp
      name: Default

# Conda 环境配置（用于 Python 任务）
conda:
  # 默认 Conda 环境
  default_env: rocm7.2
  # 可用的环境列表
  available_envs:
    - rocm7.2
    - base
  # Conda 路径
  conda_path: /home/user/miniconda3

# 资源限制
resources:
  # 最大并发任务数
  max_concurrent_tasks: 1
  # 内存限制（MB），0 表示不限制
  memory_limit: 0
  # GPU 利用率限制（0-100），0 表示不限制
  gpu_utilization_limit: 95
