# Changelog

All notable changes to Shepherd will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [v0.3.1] - 2026-02-26

### Added
- **扩展模型加载参数**: 新增 11 个 llama.cpp 服务器参数支持
  - **采样参数**: `reranking`, `minP`, `presencePenalty`, `frequencyPenalty`
  - **模板和处理**: `disableJinja` (--no-jinja), `chatTemplate` (--chat-template), `contextShift` (--context-shift)
  - **KV 缓存配置**: `kvCacheTypeK` (--kv-cache-type-k), `kvCacheTypeV` (--kv-cache-type-v), `kvCacheUnified` (--kv-unified), `kvCacheSize` (--kv-cache-size)
  - 前端 LoadModelDialog 完整支持所有新参数配置
  - 后端 BuildCommandFromRequest 支持所有新参数
- **日志系统增强**:
  - 所有日志自动包含调用位置（文件名:行号）
  - 日志格式调整: `[时间] [文件:行号] 级别 消息` (文本格式) / `{"time":"...","caller":"...","level":"...","msg":"..."}` (JSON 格式)
  - 模型加载/卸载过程添加详细日志记录
- **开发体验改进**:
  - 更新 .gitignore，排除 AI 编辑器配置文件（.claude/, .sisyphus, .cursor/ 等）
  - CLAUDE.md 文档添加到版本控制

### Fixed
- **参数兼容性**: 禁用 llama-server 不支持的参数
  - `--logits-all` 仅适用于 llama-cli，不适用于 llama-server
  - `--dio` 需要特定文件系统支持，默认禁用
- **类型同步**: 更新 `toProcessLoadRequest` 转换函数，确保所有新字段正确传递
- **测试更新**: 更新测试用例以反映禁用的参数

### Technical Details
- **支持的参数映射**:
  - `reranking: boolean` → `--reranking`
  - `minP: float64` → `--min-p <value>`
  - `presencePenalty: float64` → `--presence-penalty <value>`
  - `frequencyPenalty: float64` → `--frequency-penalty <value>`
  - `disableJinja: boolean` → `--no-jinja`
  - `chatTemplate: string` → `--chat-template <value>`
  - `contextShift: boolean` → `--context-shift`
  - `kvCacheTypeK: string` → `--kv-cache-type-k <value>`
  - `kvCacheTypeV: string` → `--kv-cache-type-v <value>`
  - `kvCacheUnified: boolean` → `--kv-unified`
  - `kvCacheSize: int` → `--kv-cache-size <value>`

---

## [v0.3.0] - 2026-02-22

### Added
- **HuggingFace SDK 集成**: 集成两个 HuggingFace Go SDK
  - `github.com/gomlx/go-huggingface/hub` - 基础 Hub 操作和文件下载
  - `github.com/bodaay/HuggingFaceModelDownloader` - 高级下载（分块/可恢复）
  - 支持基础下载模式（Basic）和高级下载模式（Advanced）
  - 添加下载进度回调支持（速度、ETA、百分比）
  - 支持多种端点（官方 HuggingFace 和 HF-Mirror）
  - 前端添加 HuggingFace 模型搜索和下载 UI
- **llama.cpp 测试功能**: 新增 `internal/client/tester` 包
  - 自动检测常见 llama.cpp 二进制路径
  - 测试二进制可执行性和版本信息
  - 支持环境变量 `LLAMACPP_SERVER_PATH`
  - 系统信息收集（GPU/CPU/ROCm）
  - 前端添加 llama.cpp 可用性测试 UI
- **配置报告功能**: 新增 `internal/client/configreport` 包
  - 收集 llama.cpp 路径配置和可用性
  - 收集模型路径和模型数量
  - 环境信息（OS/Kernel/Python/Go 版本）
  - Conda 配置和执行器配置
  - 前端添加节点配置信息展示
- **NodeAdapter API 增强**:
  - `POST /api/nodes/:id/test-llamacpp` - 测试 llama.cpp 可用性
  - `GET /api/nodes/:id/config` - 获取节点配置信息
- **配置验证测试**: 添加模式验证测试
  - 验证所有有效模式（standalone, hybrid, master, client）
  - 验证无效模式拒绝
- **路径更新测试**: 添加 `TestHandler_UpdateLlamaCppPath` 测试
  - 测试 originalPath 匹配策略
  - 测试按名称匹配
  - 测试错误场景
- **前端类型系统**: `web/src/types/node.ts` 新增配置相关类型
  - `NodeConfigInfo` - 节点配置信息
  - `LlamaCppPathInfo` - llama.cpp 路径信息
  - `ModelPathInfo` - 模型路径信息
  - `EnvironmentInfo` - 环境信息
  - `CondaConfigInfo` - Conda 配置
  - `ExecutorConfigInfo` - 执行器配置

### Changed
- **路径更新逻辑改进**: 三级匹配策略
  - 最高优先级：`originalPath` 精确匹配
  - 中等优先级：按 `name` 匹配
  - 最低优先级：按 `path` 精确匹配
- **配置验证**: 添加 `standalone` 到有效模式列表
  - 默认模式从 `hybrid` 改为 `standalone`
  - 支持所有四种模式：standalone, hybrid, master, client
- **配置废弃标记**: 为旧的 Client/Master 配置添加废弃注释
  - `ClientConfig` 标记为废弃，建议使用 `Node.ClientRole`
  - `MasterConfig` 标记为废弃，建议使用 `Node.MasterRole`
- **前端配置管理**: 改进配置加载和重载逻辑
  - 支持运行时后端切换
  - 添加配置验证
- **LoadModelDialog 重构**: 改进模型加载对话框
  - 添加 llama.cpp 测试按钮
  - 改进参数配置界面
  - 优化布局和交互
- **Settings 页面增强**: 重新组织配置项
  - 添加环境信息显示
  - 改进配置保存逻辑

### Fixed
- **路径配置 500 错误**: 修复配置验证拒绝 `standalone` 模式的问题
- **路径更新功能**: 修复 `UpdateModelPath` 和 `UpdateLlamaCppPath` 的匹配逻辑
  - 改进路径规范化处理
  - 添加更好的错误消息
- **错误消息一致性**: 统一错误响应格式
- **下载页面**: 修复下载进度显示问题
  - 添加速度和 ETA 显示
  - 支持暂停/恢复下载

### Technical Details
- **下载模式**:
  - `DownloadModeBasic`: 使用 `go-huggingface/hub`（简单可靠）
  - `DownloadModeAdvanced`: 使用 `bodaay/HuggingFaceModelDownloader`（分块、可恢复）
- **路径匹配**: 使用规范化路径进行对比，避免符号链接等问题
- **测试覆盖**: 新增 5+ 个测试函数，覆盖下载、测试、配置验证
- **新增依赖**: 两个 HuggingFace Go SDK
- **API 新增命令**:
  - `CommandTypeTestLlamacpp` - 测试 llama.cpp
  - `CommandTypeGetConfig` - 获取节点配置

---

## [Unreleased]

## [v0.2.0] - 2026-02-22

### Breaking Changes
- **API 路由统一**: `/api/master/clients/*` 和 `/api/master/nodes/*` 统一为 `/api/nodes/*`
  - 旧路由已标记为废弃，将在 v0.4.0 移除
  - 旧路由返回 `X-API-Deprecation` 和 `X-API-Sunset` 响应头
- **前端类型重构**: `Client` 类型迁移到 `UnifiedNode`
  - `web/src/types/cluster.ts` 标记为 `@deprecated`
  - 建议使用 `web/src/types/node.ts` 中的统一类型

### Added
- **统一类型系统**: `internal/types/node.go` 新增统一节点类型定义
  - `NodeCapabilities` - 节点能力（GPU/CPU/内存/软件支持）
  - `NodeResources` - 节点资源使用情况
  - `NodeInfo` - 统一节点信息（兼容 Master/Client/Node）
  - `HeartbeatMessage` - 统一心跳消息
  - `Command` 和 `CommandResult` - 统一命令结构
- **类型别名系统**: 保持向后兼容
  - `internal/node/types.go`: `NodeInfo` → `types.NodeInfo`
  - `internal/cluster/types.go`: `Client` → `types.NodeInfo`
- **前端统一类型**: `web/src/types/node.ts` 新增 `UnifiedNode` 接口
- **API 响应辅助函数**: `internal/api/response.go` 提供统一响应格式
  - `Success()`, `Error()`, `ValidationError()`, `NotFound()` 等
- **任务类型定义**: `web/src/types/task.ts` 新增任务相关类型

### Changed
- **NodeAdapter 路由重构**: 主路由使用 `/api/nodes/*`
  - `RegisterRoutes()` 方法重构
  - 添加 `registerDeprecatedRoutes()` 处理旧路由
  - 添加 `deprecationWarningMiddleware()` 废弃警告中间件
- **前端类型导出**: `web/src/types/index.ts` 重新组织导出
- **客户端组件更新**: 修复可选字段空值处理

### Fixed
- 修复前端 `ClientCard` 组件可选字段空值访问问题
- 统一前后端类型定义，消除重复

### Technical Details
- **后端类型统一**: 新建 `internal/types/node.go` 作为唯一类型定义来源
- **前端类型统一**: `web/src/types/node.ts` 的 `UnifiedNode` 作为推荐类型
- **向后兼容策略**: 使用类型别名保持现有代码无需修改
- **API 废弃策略**: HTTP 响应头 + 日志警告 + 文档标记

### Migration Guide

**后端迁移**:
```go
// 旧代码
import "github.com/shepherd-project/shepherd/internal/node"
nodeInfo := node.NodeInfo{...}

// 新代码（推荐）
import "github.com/shepherd-project/shepherd/internal/types"
nodeInfo := types.NodeInfo{...}

// 旧代码仍可编译（类型别名）
nodeInfo := node.NodeInfo{...} // 等同于 types.NodeInfo
```

**前端迁移**:
```typescript
// 旧代码
import type { Client } from '@/types/cluster';

// 新代码（推荐）
import type { UnifiedNode } from '@/types/node';

// 旧代码仍可编译（类型别名）
import type { Client } from '@/types/cluster'; // 等同于 UnifiedNode
```

**API 路由迁移**:
```bash
# 旧路由（已废弃）
GET /api/master/clients
GET /api/master/nodes

# 新路由（推荐）
GET /api/nodes
```

## [v0.1.4] - 2026-02-22

### Added
- 模型性能测试页面自动加载默认 llama.cpp 路径的设备信息
- 设备列表解析时添加严格的前缀验证 (ROCm/CUDA/Vulkan/Metal)

### Changed
- 优化 BenchmarkDialog 的 useEffect 执行顺序，确保设备检测自动触发

### Fixed
- 修复设备列表解析错误匹配调试信息导致重复设备的问题
  - llama.cpp --list-devices 输出包含 stderr 调试信息
  - 修复前: 解析了 "ggml_cuda_init: found 1 ROCm devices" 导致重复
  - 修复后: 只解析 "Available devices:" 标记后的正式设备列表
- 修复性能测试对话框打开后设备不自动加载的问题
  - 调整 useEffect 顺序，确保设备检测在初始化之前执行

### Technical Details
- **设备检测改进**: `parseDeviceList()` 现在只在找到 "Available devices:" 标记后开始解析
- **设备验证**: 添加 `validDevicePrefix()` 方法验证设备前缀格式
- **前端优化**: BenchmarkDialog useEffect 顺序重构，确保自动加载

## [v0.1.3] - 2026-02-19

### Added
- 配置管理 API (llama.cpp 和模型路径)
- 下载管理器完整实现
- 进程管理 API
- 脚本重组 (linux/macos/windows)

### Changed
- Web 前端完全独立于后端配置
- 路径配置功能从设置页面移到独立配置

## [v0.1.2] - 2026-02-15

### Added
- Web 前端独立架构
- 前端独立配置文件 (web/config.yaml)
- 多后端支持和运行时切换
- SSE 实时事件推送

## [v0.1.1] - 2026-02-10

### Added
- Master-Client 分布式架构
- 统一 Node 模型
- 心跳和资源监控
- 命令分发和调度

## [v0.1.0-alpha] - 2026-02-01

### Added
- 核心功能实现
- GGUF 模型扫描和管理
- OpenAI/Anthropic/Ollama API 兼容
- Web UI 基础功能
